{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Neural Networks are one of the most used tools in machine learning. Basically, what we are doing is putting together many perceptrons into layers for a more complex system. Here, I will be using an input layer (64 nodes) -> a hidden layer (5 nodes) -> output layer (10 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 65)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "x = digits.data\n",
    "\n",
    "# Adding a bias term\n",
    "temp = []\n",
    "for i in range(len(x)):\n",
    "    temp.append(x[i])\n",
    "    temp[i] = np.append(temp[i], 1)\n",
    "\n",
    "x = np.array(temp)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   55   56   57  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    58    59    60    61   62   63   64  \n",
       "0  6.0  13.0  10.0   0.0  0.0  0.0  1.0  \n",
       "1  0.0  11.0  16.0  10.0  0.0  0.0  1.0  \n",
       "2  0.0   3.0  11.0  16.0  9.0  0.0  1.0  \n",
       "3  7.0  13.0  13.0   9.0  0.0  0.0  1.0  \n",
       "4  0.0   2.0  16.0   4.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that since each row is an 8x8 picture, it has 64 columns in it\n",
    "# Each row is an image\n",
    "pd.DataFrame(x).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10,15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x[range(1500)]\n",
    "train_y = y[range(1500)]\n",
    "\n",
    "test_x = x[range(1500, 1797)]\n",
    "tesy_y = y[range(1500, 1797)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def σ(z):\n",
    "    \"\"\"\n",
    "    Sigmoid Function that takes in a number, z, and outputs\n",
    "    the sigmoid function evaluated at z, which is in the\n",
    "    interval [0, 1]\n",
    "    \"\"\"\n",
    "    return (1 + np.exp(-z))**(-1)\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    Loss function that takes in two arrays of equal length,\n",
    "    y and y_hat, and calculates the sum of squares loss between\n",
    "    the two\n",
    "    \"\"\"\n",
    "    return sum((y - y_hat)**2)\n",
    "\n",
    "def gradient_w2(y_hat, y, hidden_layer, w2, α):\n",
    "    \"\"\"\n",
    "    Function to calculate the gradient for any one of the set of\n",
    "    weights between the hidden layer and one output node\n",
    "    INPUTS:\n",
    "        - y_hat, the calculation of output node k\n",
    "        - y, the target value for output node k\n",
    "        - w2, the array of weights that go from the hidden layer\n",
    "            to one of the output nodes k\n",
    "        - α, the learning rate\n",
    "    OUTPUTS:\n",
    "        - w2_new, an array of new weights for the weights\n",
    "                between layer two and output node k\n",
    "    \"\"\"\n",
    "    gradient = []\n",
    "    for j in range(len(w2)):\n",
    "        gradient.append(2 * (y - y_hat) * y_hat * (1 - y_hat) * hidden_layer[j])\n",
    "    gradient = np.array(gradient)\n",
    "    \n",
    "    w2_new = w2 - (α * gradient)\n",
    "    return w2_new\n",
    "    \n",
    "def gradient_w1(y_vals, y_hats, w2_j, node_j, x, w1, α):\n",
    "    \"\"\"\n",
    "    Function to calculate the gradient for any one of the set of\n",
    "    weights between the input layer and one hidden layer node\n",
    "    INPUTS:\n",
    "        - y_vals, the target outputs for the output layer\n",
    "        - y_hats, the calculated values for the output layer\n",
    "        - w2_j, an array of each of the weights from node j\n",
    "                to the outputs\n",
    "        - node_j, the value of node j of the hidden layer\n",
    "        - x, the input values used in the feed forward algorithm\n",
    "        - w1, a set of weights from all the input nodes to node j\n",
    "             in the hidden layer\n",
    "        - α, the learning rate with which to scale the change in weights\n",
    "        \n",
    "    OUTPUTS:\n",
    "        - w1_new, an array of new weights \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for k in range(10):\n",
    "        total += (y_vals[k] - y_hats[k]) * y_hats[k] * (1 - y_hats[k]) * w2_j[k]\n",
    "        \n",
    "    gradient = total * 2 * node_j * (1 - node_j) * x\n",
    "     \n",
    "    w1_new = w1 - (α * gradient)\n",
    "    return w1_new\n",
    "\n",
    "def feed_forward(x, w1, w2):\n",
    "    \"\"\"\n",
    "    Function to feed forward the array, x, and give outputs\n",
    "    INPUTS:\n",
    "        - x, an array of length 64, the data to be passed through\n",
    "        - w1, the matrix holding all the weights from the input\n",
    "            layer to the hidden layer\n",
    "        - w2, the matrix holding all the weights from the hidden layer\n",
    "            to the output layer\n",
    "    OUTPUTS:\n",
    "        - outputs, an array of length 10\n",
    "        - hidden_layer, an array of length 5\n",
    "    \"\"\"\n",
    "    hidden_layer = []\n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        hidden_layer.append(σ(np.dot(w1[:,i], x)))\n",
    "    hidden_layer.append(1)\n",
    "        \n",
    "    for i in range(10):\n",
    "        z = np.dot(w2[:,i], np.array(hidden_layer))\n",
    "        outputs.append(σ(z))\n",
    "        \n",
    "    return {'o':outputs, 'hl':hidden_layer}\n",
    "\n",
    "def NeuralNet(x, y, weights1, weights2, num_iterations=100, α=0.25):\n",
    "    \"\"\"\n",
    "    Function for optimizing the weights for the 3-layer Neural Network\n",
    "    INPUTS:\n",
    "        - x, the input data matrix with size m x n, where each row \n",
    "            is an observations\n",
    "        - y, an array of length m with all the correct classifications\n",
    "            of the data in x\n",
    "        - weights1, a matrix of size 65 x 6, where each column is a set of weights\n",
    "            corresponding to one of the hidden layer nodes\n",
    "        - weights2, a matrix of size 6 x 10, where each column is a set of weights\n",
    "            corresponding from the hidden layer to one of the output nodes\n",
    "        - num_iterations, an integer, the maximum number of iterations\n",
    "                        the algorithm will perform before stopping\n",
    "        - α, the learning rate for the algorithm\n",
    "    OUTPUTS:\n",
    "        - new_w1, the optimized weights for the first layer\n",
    "        - new_w2, the optimized weights for the second layer\n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    n = len(x[0])\n",
    "    j = 0\n",
    "    \n",
    "    w1 = weights1\n",
    "    w2 = weights2\n",
    "    error = []\n",
    "    while (j <= num_iterations):\n",
    "        j+=1\n",
    "        \n",
    "        # Feed Forward\n",
    "        num_incorrect = 0\n",
    "        for i in range(n):\n",
    "            obs = x[i]\n",
    "            target = y[i]\n",
    "            \n",
    "            ff = feed_forward(x[i], w1, w2)\n",
    "            y_hats = ff['o']\n",
    "            hidden_layer = ff['hl']\n",
    "            guess = np.argmax(np.array(y_hats))\n",
    "            \n",
    "            # Back Propagation\n",
    "            target_y = np.zeros(10)\n",
    "            target_y[target] = 1\n",
    "            \n",
    "            if (guess != y[i]):\n",
    "                \n",
    "                # Updating the weights between the hidden layer and the output layer\n",
    "                for k in range(10):\n",
    "                    w2[:,k] = gradient_w2(y_hats[k], target_y[k], hidden_layer, w2[:,k], α)\n",
    "        \n",
    "                # Updating the weights between the input layer and the hidden layer\n",
    "                for k in range(6):\n",
    "                    w1[:,k] = gradient_w1(target_y, y_hats, w2[k,:], hidden_layer[k], obs, w1[:,k], α)\n",
    "            \n",
    "    \n",
    "    return w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4780459 , 0.32594404, 0.57198452, 0.38037328, 0.51216572,\n",
       "       0.06949404, 0.62866751, 0.48907987, 0.87192241, 0.28285776])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights between the input layer and layer 2\n",
    "weights1 = np.random.random((64+1)*6).reshape(65, 6)\n",
    "\n",
    "# Weights between layer 2 and the output layer\n",
    "weights2 = np.random.random((5+1)*10).reshape(6, 10)\n",
    "weights2[0,:]\n",
    "# This would represent all of the weights from the first node in the \n",
    "# hidden layer to the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = NeuralNet(train_x, train_y, weights1, weights2, num_iterations=100, α=.5)\n",
    "w1 = weights[0]\n",
    "w2 = weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ec545f69b223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w1' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(w1, w2, x):\n",
    "    \"\"\"\n",
    "    Function to predict what number observation x\n",
    "    is based on the given weights w1 and w2\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
